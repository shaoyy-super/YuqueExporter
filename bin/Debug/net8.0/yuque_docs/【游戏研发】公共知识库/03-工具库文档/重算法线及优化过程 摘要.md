# 一.问题背景
## 问题简述
当骨骼大幅度的不均匀缩放后，由于法线问题，导致视觉上凹凸感错误。

如下图表，我们将模型腹部的一个骨骼节点的缩放值调到4，对比错误（默认表现）和正确（算法修正后）的表现，同时我们使用2cm的线，画出模型空间下，每个顶点的法线方向，同时用线的颜色(RGB)来表示法线方向(XYZ)。



可以看到，左侧模型从正面看，腹部仍然是平的。

| 默认的错误表现（从上到下：侧面，正面，模型空间法线） | 修正后的正确表现（从上到下：侧面，正面，模型空间法线） |
| --- | --- |
| ![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134058774-e17bc016-7dad-452a-95e2-5ac546c0e309.png) | ![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134057378-d71c0329-ac21-476a-b380-2b272a7a7df0.png) |
| ![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134057097-159dc674-52db-46c7-a083-b1359117bcdb.png) | ![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134056772-553125a5-e0e3-4ed1-949b-a53607637e47.png) |


后文将逐步的分析解决问题，在移动端高效的，将左侧默认的错误表现，修正为右侧正确的表现。



## 法线概念
问题：为了能够理解后续的内容，需要先明细关于法线/法线贴图的基本概念。

详情：

[重算法线及优化过程](https://snh48group.yuque.com/org-wiki-snh48group-ec9yge/rgqlf2/hb1tcigvxgp5zcim#cWFKj)

结论：顶点法线通过影响光照产生凹凸视觉表现。法线贴图通过RGB存储向量信息，干扰法线，使低模表现出高模细节。

## 问题成因分析
问题：为了解决表现错误问题，需要先知道问题产生的原因，及其实现逻辑，为此我们将详细的分析顶点骨骼蒙皮的实现过程。

详情：

[重算法线及优化过程](https://snh48group.yuque.com/org-wiki-snh48group-ec9yge/rgqlf2/hb1tcigvxgp5zcim#wSdAU)

结论：SkinnedMeshRenderer会像处理顶点位置一样，通过骨骼的变换矩阵及权重，将顶点的法线转化为世界坐标，但是这个转化过程不考虑缩放。





# 二.法线重计算整体流程
## 基本思路
问题：为了使表现正确，需要重新计算被骨骼缩放后影响后顶点法线，并覆盖mesh中保存的顶点法线。

详情：

[重算法线及优化过程](https://snh48group.yuque.com/org-wiki-snh48group-ec9yge/rgqlf2/hb1tcigvxgp5zcim#OgxJF)

结论：clone出一个保存TPose的模型，同步进行捏人，再由此bake出一个mesh，从烘焙出mesh计算法线，将计算结果赋值给目标模型。

## 轴向偏差
问题：表现错误

详情：

[重算法线及优化过程](https://snh48group.yuque.com/org-wiki-snh48group-ec9yge/rgqlf2/hb1tcigvxgp5zcim#IhgnS)

结论：通过一些可视化手段，观察到原因为模型空间与unity世界坐标空间存在90度偏差，从而导致了法线方向存在轴向偏差。

## 非共享顶点的法线平滑
问题：SubMesh接缝/UV接缝处存在法线不平滑的问题

详情：

[重算法线及优化过程](https://snh48group.yuque.com/org-wiki-snh48group-ec9yge/rgqlf2/hb1tcigvxgp5zcim#QKJZx)

结论：在此再次明晰软边与硬边的概念，及什么是非共享顶点。unity提供的计算接口不支持非共享顶点的法线计算，需要自行处理接缝。

# 三.V0:支持非共享顶点的法线平滑算法
问题：需要自实现一套支持接缝法线平滑的算法。

详情：

[重算法线及优化过程](https://snh48group.yuque.com/org-wiki-snh48group-ec9yge/rgqlf2/hb1tcigvxgp5zcim#NptC7)

结论：通过抽象出位置点概念，收集处于同一位置的非共享顶点，对其法线尝试进行平均。表现符合预期，接缝处法线得到平滑处理。但算法执行耗时过大，需要优化。



# 四. 性能优化
## V1: Unity+Custom
unity的计算接口更快，我们没必要计算所有顶点的法线，只需要计算接缝顶点法线即可。

详情：

[重算法线及优化过程](https://snh48group.yuque.com/org-wiki-snh48group-ec9yge/rgqlf2/hb1tcigvxgp5zcim#UXBhk)



## V2：Unity + Custom_Job
用jobs对V1进行优化，效果不是很好，踩了一些坑，总结出一些关于多线程并行的经验。

详情：

[重算法线及优化过程](https://snh48group.yuque.com/org-wiki-snh48group-ec9yge/rgqlf2/hb1tcigvxgp5zcim#xnuTJ)

## V3：Unity+Custom_NewData
剥离位置点顶点收集的过程，将其移动到换装时。

详情：

[重算法线及优化过程](https://snh48group.yuque.com/org-wiki-snh48group-ec9yge/rgqlf2/hb1tcigvxgp5zcim#d8dof)

结论：换装时刷新数据耗时过高，法线计算本身耗时大幅下降。



## V4：Unity+Custom_NewData_Job
剥离位置点顶点收集的过程，将其预处理。采用burst和jobs对算法进行优化。

详情：

[重算法线及优化过程](https://snh48group.yuque.com/org-wiki-snh48group-ec9yge/rgqlf2/hb1tcigvxgp5zcim#qfpVw)





Busrt的用法讨论:

[重算法线及优化过程](https://snh48group.yuque.com/org-wiki-snh48group-ec9yge/rgqlf2/hb1tcigvxgp5zcim#KSPlA)

## V5：计算1个位置点下所有顶点的法线为最小单位
问题：V4的job以计算1个顶点的法线作为最小单位，粒度过小，数据组织过程较为复杂

方案：采用计算1个位置点所有顶点的法线为最小单位，因为1个顶点不可能即在A位置点，又在B位置点，所以这样也能避免写入竞争。

详情：

![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1730690011136-b406f9d2-77a9-476f-80f3-cd453fc685e7.png)

结论：由于更改了最小计算单位，所以少了几个中转索引的数据结构。所以顶点法线计算耗时，换装时数据重新组织数据耗时，都得到了小幅度优化。



最终V5版本的代码实现，相对前几个版本更为精简高效：

```plain
        [BurstCompile]
        [MethodImpl(MethodImplOptions.NoInlining)]
        static void FillEntryList3([NoAlias]ref NativeHashMap<int3, int> entrysWithJob,
                                 [NoAlias]ref NativeList<int> triIdxListWithJob,
                                 [NoAlias] ref NativeList<FixedList512Bytes<int2>> valueList,
                                 [NoAlias] ref NativeList<int> needRecalculateVerticeListWithJob,
                                 [NoAlias] ref MeshArgs2 meshArgs
                                  )
        { 
            int idxStart = meshArgs.idxStart;
            int triCount = triIdxListWithJob.Length / 3;
            var startIdx = triIdxListWithJob.Length;
            triIdxListWithJob.Resize(triIdxListWithJob.Length + meshArgs.triCount, NativeArrayOptions.UninitializedMemory);
            for (int i = 0; i < meshArgs.triCount; i++)
            { 
                triIdxListWithJob[startIdx + i] = meshArgs.tris[i] + idxStart;
            }

            startIdx = needRecalculateVerticeListWithJob.Length;
            needRecalculateVerticeListWithJob.Resize(needRecalculateVerticeListWithJob.Length + meshArgs.versCount, NativeArrayOptions.UninitializedMemory);
            for (int i = 0; i < meshArgs.versCount; i++)
            { 
                needRecalculateVerticeListWithJob[startIdx + i] = meshArgs.vers[i] + idxStart;
            }

            int offfset = 0;
            int2 entryOffset = new int2(triCount, idxStart);
            for (int i = 0; i < meshArgs.entryKeyCount; i++)
            {
                var intKey = meshArgs.entryKeyList[i];
                bool has = entrysWithJob.ContainsKey(intKey);
                int idx = has ? entrysWithJob[intKey] : -1;
                var list =  has ? valueList[idx] : new FixedList512Bytes<int2>();
                var count = meshArgs.entryCountList[i];
                for (int j = 0; j < count; j++)
                    list.Add(meshArgs.entryValueList[j + offfset] + entryOffset);
                if (has)
                    valueList[idx] = list;
                else
                { 
                    entrysWithJob.Add(intKey, valueList.Length);
                    valueList.Add(list);
                }
                offfset += count;
            }
        }
```



```plain
public class NormalSolver8
{
    public static JobHandle CustomRecalculateNormals(NativeArray<VertexStruct> vertices, 
                                                     NativeList<int> triList, 
                                                     NativeArray<float3> triNormalList, 
                                                     NativeList<FixedList512Bytes<int2>> valueList, 
                                                     float cosineThreshold)
    {
        
        var job = CalculateTriNormal(vertices, triList, triNormalList);
        return CalculateSmoothNormal(vertices ,triNormalList, valueList, cosineThreshold, job);
    }

    [BurstCompile(CompileSynchronously = true)]
    struct CalculateSmoothNormalJob : IJobParallelFor
    {
        public float cosineThreshold;
        [ReadOnly]
        public NativeArray<float3> triNormalList;

        [WriteOnly]
        [NativeDisableContainerSafetyRestriction]
        public NativeArray<VertexStruct> verticeList;
        [ReadOnly]
        public NativeList<FixedList512Bytes<int2>> valueList;
        public void Execute(int idx)
        {
            var entryList = valueList[idx];
            for (var i = 0; i < entryList.Length; ++i)
            {
                var lhsEntry = entryList[i];
                if (verticeList[lhsEntry[1]].pos.x > 9999)
                    continue;
                float3 sum = 0.0f;
                for (var j = 0; j < entryList.Length; ++j)
                {
                    var rhsEntry = entryList[j];
                    if (lhsEntry[1] == rhsEntry[1])
                        sum += triNormalList[rhsEntry[0]];
                    else
                    {
                        var lNormal = triNormalList[lhsEntry[0]];
                        var rNormal = triNormalList[rhsEntry[0]];
                        var dot = math.dot(lNormal, rNormal);
                        if (dot >= cosineThreshold)
                            sum += rNormal;
                    }
                }

                var vert = verticeList[lhsEntry[1]];
                vert.normal = math.normalizesafe(sum);
                vert.pos.x = 10000;
                verticeList[lhsEntry[1]] = vert;
            }
        }
    }

    [BurstCompile(CompileSynchronously = true)]
    struct CalculateTriNormalJob : IJobParallelFor
    {
        [ReadOnly]
        public NativeList<int> triangleVertexArr;
        [ReadOnly]
        public NativeArray<VertexStruct> verticeList;

        [WriteOnly]
        [NativeDisableContainerSafetyRestriction]
        public NativeArray<float3> triNormalList;

        public void Execute(int idx)
        {
            int i1 = triangleVertexArr[idx * 3];
            int i2 = triangleVertexArr[idx * 3 + 1];
            int i3 = triangleVertexArr[idx * 3 + 2];
            float3 p1 = (verticeList[i2].pos - verticeList[i1].pos) * 10000;
            float3 p2 = (verticeList[i3].pos - verticeList[i1].pos) * 10000;
            float3 normal = math.normalizesafe(math.cross(p1, p2));
            triNormalList[idx] = normal;
        }
    }

    static JobHandle CalculateTriNormal(NativeArray<VertexStruct> vertices, NativeList<int> triList, NativeArray<float3> triNormalList)
    {
        CalculateTriNormalJob job = new CalculateTriNormalJob();
        job.triangleVertexArr = triList;
        job.triNormalList = triNormalList;
        job.verticeList = vertices;
        var handle = job.Schedule(triList.Length/3, 32);
        return handle;
    }
    
    static JobHandle CalculateSmoothNormal(NativeArray<VertexStruct> vertices, 
                                           NativeArray<float3> triNormalList, 
                                           NativeList<FixedList512Bytes<int2>> valueList,  
                                           float cosineThreshold, 
                                           JobHandle depHandle)
    {
        CalculateSmoothNormalJob job = new CalculateSmoothNormalJob();
        job.verticeList = vertices;
        job.cosineThreshold = cosineThreshold;
        job.triNormalList = triNormalList;
        job.valueList = valueList;
        var handle = job.Schedule(valueList.Length, 8, depHandle);
        return handle;
    }
}

```

## 性能优化效果总结
为了更准确的得到优化效果，降低偶然性，使用UWA进行真机性能打点测试：

![UWA测试结果](https://cdn.nlark.com/yuque/0/2024/png/43256925/1730799638444-8280ea3a-a4af-4b40-9f95-2e097576d2cb.png)

测试环境：<font style="background-color:#FBDE28;">RedmiNote 10Pro，天玑1100</font>

![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1730456856973-9f7de6a8-3b8b-42ca-9521-94d9437176f8.png)



数据规模：55个接缝，1319个接缝顶点，2556个接缝三角形。最新的裸模接缝顶点相较于当前测试的数据规模会有所升高。



算法执行次数：800次



平均单次耗时表：

|  | 算法耗时（ms） | UnityAPI（ms） | 刷新数据-换装时（ms） |
| --- | --- | --- | --- |
| V0（自行计算所有顶点的法线） | 112.94 | 0 | 0 |
| V1（先用unity计算，再自行计算接缝） | 8.02 | 1.75 | 0 |
| V2（使用Job对接缝处法线计算进行优化） | 6.85 | 1.77 | 0 |
| V3（换装时计算entryMap，无Job） | 1.10 | 1.91 | 4.36 |
| V4（预处理entryMap，换装时合并，使用多线程Job+Burst） | 0.51 | 1.73 | 0.87 |
| V5（在V4的基础上，改变最小计算单位） | 0.43 | 1.77 | 0.68 |




V1

优化效果：112.94ms--->8.02ms

优化方案：大幅度减少需要计算的顶点，只自行计算处理接缝处的顶点。从自行计算17486个顶点的法线，缩减为只处理55个接缝处1319个顶点的法线。

启发：数据批量相对较大，需要尝试使用jobs多线程处理。



V2

优化效果：8.02ms--->6.85ms

优化方案：每个接缝开Job，分成 三角形法线计算Job 和 顶点法线平滑Job

启发：法线Jobs的多线程用法不对，entryMap收集频率不合理，Native数据结构和托管数据结构的转化问题



V3

优化效果：6.85ms--->1.10ms    

   0ms--->4.36ms(刷新数据)

优化方案：将entryMap的收集抽出去，放到换装结束时。未使用job。

启发：刷新数据耗时过高，法线计算在主程序耗时1.13ms，有尝试多线程的必要。



V4：

优化效果：1.10ms--->0.51ms    

   4.36ms--->0.87ms(刷新数据)

优化方案：正确使用多线程计算法线。将位置点和顶点的归属关系，提前序列化下来。

启发：job粒度过小，在避免竞争的前提下，有粒度更大的方式。



V5：

优化效果：0.51ms--->0.43ms    

   0.87ms--->0.68ms(刷新数据)

优化方案：计算一个位置点的所有顶点法线作为最小计算单位，提高每个job的工作量，减少job批次数量，减少几个中间转化索引的数据结构。

添加Unity.Burst.CompilerServices.Loop.ExpectVectorized进行检测，并优化两个循环至可向量化。

