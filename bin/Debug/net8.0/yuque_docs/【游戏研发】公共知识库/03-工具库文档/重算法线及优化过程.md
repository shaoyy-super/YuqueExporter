# 一.问题背景
## 问题简述
当骨骼大幅度的不均匀缩放后，由于法线问题，导致视觉上凹凸感错误。

如下图表，我们将模型腹部的一个骨骼节点的缩放值调到4，对比错误（默认表现）和正确（算法修正后）的表现，同时我们使用2cm的线，画出模型空间下，每个顶点的法线方向，同时用线的颜色(RGB)来表示法线方向(XYZ)。



可以看到，左侧模型从正面看，腹部仍然是平的。

| 默认的错误表现（从上到下：侧面，正面，模型空间法线） | 修正后的正确表现（从上到下：侧面，正面，模型空间法线） |
| --- | --- |
| ![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134058774-e17bc016-7dad-452a-95e2-5ac546c0e309.png) | ![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134057378-d71c0329-ac21-476a-b380-2b272a7a7df0.png) |
| ![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134057097-159dc674-52db-46c7-a083-b1359117bcdb.png) | ![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134056772-553125a5-e0e3-4ed1-949b-a53607637e47.png) |


后文将逐步的分析解决问题，在移动端高效的，将左侧默认的错误表现，修正为右侧正确的表现。



## 关于法线的基本知识
这里先简单的说一下，什么是法线及法线贴图，方便后文理解我们为什么要平滑法线。

如下图，有两个顶点结构一样的柱体。

明显的，左边看上去是个多棱柱，右边看上去是个圆柱。

这是因为，法线方向通过参与光照计算，来欺骗人的视觉。

![相同顶点位置的两个柱体（左侧硬边，右侧软边）](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134056507-159742c3-12d9-45a4-92be-885b391b1a83.png)



如下图左侧硬边柱体法线示意图，可以看到，转角处顶点的一个位置上有两个不同方向的法线，分别垂直于各自所在的面。

![左侧硬边柱体法线示意](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134068802-e1005589-772d-4ab9-9aab-059f5d02a465.png)



如下图右侧软边柱体法线示意图，可以看到，在转角处的顶点，仅有一个法线方向，它由两个面法线平均而来。

![右侧软边柱体法线示意](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134068793-21b262fe-a4ba-4b5b-9463-808d32598bf6.png)

****

![转角法线对比](https://cdn.nlark.com/yuque/0/2024/png/43256925/1730701721286-400e8790-2f77-44cf-beff-a9cc180f4eb6.png)

接着我们顺便说一下法线贴图，避免概念上的混淆。

法线贴图是通过贴图的颜色信息，转化为向量信息，以此对模型中的顶点法线方向进行干预，干扰，达到以低模呈现出高模细节的目的。

![高模烘焙法线给低模使用](https://cdn.nlark.com/yuque/0/2024/png/43256925/1730701533660-7a5db7bb-ce62-4f83-81ef-5efc945cb816.png)

Unity中，法线贴图一般采用UV坐标采样，将对应位置的像素颜色RGB信息，转化为法线方向的三个轴的数值。

法线方向是单位化的，所以<font style="background-color:#FBDE28;">RGB三个通道的0到255</font>，对应表示<font style="background-color:#FBDE28;">法线方向的三个轴向的-1到1</font>。

0到128的表示-1到0，用128到255的方向，表示0到1。

由于大部分地方都不需要干扰，法线方向就是垂直于所在面，即（0，0，1），转化为颜色值即（128，128，255），这个就是法线贴图的背景色。

下图可以很好的表示法线贴图的工作原理：

![法线贴图工作原理示意](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134068804-4e6d8901-95be-41c3-8617-029eb462474a.png)

![法线贴图示例](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134068794-d58f770e-b8fa-4e6d-9e10-314651e81a0e.png)

![在法线贴图干扰下，圆柱表现出来凹凸细节](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134068993-4a9de9ea-98dd-420d-a736-6bb530bc4500.png)



诸如opengl和DX颜色通道的读取规则，以及如何烘焙法线贴图等问题，法线为什么采用UV坐标采样，什么是切线等问题不再讨论，感兴趣的同学可以前往：

[https://zhuanlan.zhihu.com/p/88873188?utm_medium=social&utm_psn=1809232233707495424&utm_source=ZHShareTargetIDMore](https://zhuanlan.zhihu.com/p/88873188?utm_medium=social&utm_psn=1809232233707495424&utm_source=ZHShareTargetIDMore)



[https://www.artstation.com/blogs/typhen/GMyG/this-is-normal-1-what-normal-maps-are-and-how-they-work](https://www.artstation.com/blogs/typhen/GMyG/this-is-normal-1-what-normal-maps-are-and-how-they-work)

这个系列文章有五篇，在脱离具体游戏引擎的情况下，详细说明了关于法线的原理及工作流。

![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134071140-3aef8da2-d191-4c89-afe6-d8e0b3a106f7.png)



## 为什么骨骼缩放会引起法线错误
如图，有两个Mesh信息相同（包括顶点，法线，切线，uv等）小球。唯一不同的是，左侧小球，是SkinnedMeshRenderer，并且有简单的骨骼结构。而右侧是MeshRender

![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134071118-85438072-fc43-4c1b-9f02-ef464ea7a2b6.png)

以下是对左侧小球进行蒙皮数据进行组织的代码

```plain
        //球的顶点数量
        var verCount = skinnedMeshRenderer.sharedMesh.vertexCount;
        //new一个新的Mesh
        var newMesh = new Mesh();
        newMesh.MarkDynamic();
        var oldMesh = skinnedMeshRenderer.sharedMesh;

        //复制模型的一切信息
        newMesh.vertices = oldMesh.vertices;
        newMesh.triangles = oldMesh.triangles;
        newMesh.tangents = oldMesh.tangents;
        newMesh.normals = oldMesh.normals;
        newMesh.uv = oldMesh.uv;
        newMesh.uv2 = oldMesh.uv2;

        //创建骨骼权重数组，数量和顶点数量相同，每一位表示对应索引顶点的骨骼权重
        boneWeights = new BoneWeight[verCount];
        for (int i = 0; i < boneWeights.Length; i++)
        {
            //使用BoneWeight来存储权重，最多支持四根骨骼
            BoneWeight boneWeight = new BoneWeight();
            //受到骨骼1的影响
            boneWeight.boneIndex0 = 1;
            boneWeight.weight0 = 0.5f;
            //受到骨骼2的影响
            boneWeight.boneIndex1 = 2;
            //四根骨骼的权重加起来需要是1
            boneWeight.weight1 = 0.5f;
            boneWeights[i] = boneWeight;
        }

        //每一个骨骼的bindPose，蒙皮过程需要
        Matrix4x4[] bindPoses = new Matrix4x4[bones.Length];
        for (int i = 0; i < bindPoses.Length; i++)
        {
            bindPoses[i] = bones[i].worldToLocalMatrix * transform.localToWorldMatrix;
        }
        //设置骨骼权重
        newMesh.boneWeights = boneWeights;
        //bindPose：模型空间转骨骼空间的矩阵
        newMesh.bindposes = bindPoses;
        //标记为可写
        newMesh.UploadMeshData(false);
        //骨骼数组
        skinnedMeshRenderer.bones = bones;
        //Mesh
        skinnedMeshRenderer.sharedMesh = newMesh;
        //根骨骼
        skinnedMeshRenderer.rootBone = bones[0];
        //计算边界
        skinnedMeshRenderer.sharedMesh.RecalculateBounds();
```



现在我们把两个球的Y轴缩放压倒0.02（左侧小球调整根骨骼缩放），这几乎是一个面片。从俯视视角观察。右边小球表现出应有的面片，但左侧小球仍然有立体感。

![左侧小球缩放压平后仍有立体感](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134071415-24c700c8-abc6-48c3-9001-6554cd224fe8.png)



打开世界坐标下法线渲染模式：

| 俯视，Y轴0.02缩放（左侧蒙皮，右侧无蒙皮） | 俯视，Y轴无缩放（左侧蒙皮，右侧无蒙皮） |
| --- | --- |
| ![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134071098-bc8cde3b-a298-4e78-a797-330c16c10296.png) | ![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724167969698-c233d501-49ff-4a12-a019-1338c17a68cf.png) |




观察上图，可以看到，无蒙皮的MeshRenderer的世界坐标法线，会跟着所在物体的缩放而修正，具体机制可以参考：[https://blog.51cto.com/u_16213688/10717212](https://blog.51cto.com/u_16213688/10717212)



而有蒙皮的SkinnedMeshRenderer小球的世界坐标法线虽然也会变化，但这个变化并不符合我们的预期。



为了后续能够更容易理解，蒙皮对顶点法线做了什么，以及我们们为什么要修改模型空间下的法线，在此我们先详细的分析，骨骼是如何控制顶点的坐标。

对于SkinnedMeshRenderer，顶点的世界坐标，是根据顶点的模型空间坐标，和对应权重的骨骼的位置旋转缩放信息，及其权重值，计算出来的：



为了使复杂问题简单化，我们先忽略多个骨骼的权重叠加问题，假设一个顶点只受一根骨骼影响。

如下图：

红色：世界坐标系

黄色：模型坐标系

白色：骨骼坐标系

绿圈：小臂上的一个顶点

mesh.vertices存放了所有顶点在TPose下，模型坐标系下的位置坐标。

![三个坐标系](https://cdn.nlark.com/yuque/0/2024/png/43256925/1730359787129-420da6b0-c979-48ec-b725-626776f5c0f0.png)



在此，我们将小臂骨骼旋转一下，在三个坐标系种，只有在骨骼坐标系下的坐标不会变化。反过来说，不管骨骼怎么变化，我们只需要在骨骼运动时<font style="background-color:#FBDE28;">保持顶点在骨骼空间坐标系下的坐标不变</font>，就完成了对该顶点的骨骼蒙皮。

![骨骼坐标系下顶点位置不变](https://cdn.nlark.com/yuque/0/2024/png/43256925/1730359833265-20863121-b294-4b3d-b464-0ca08c3e99b7.png)



如下图，我们根据顶点的模型空间坐标，通过世界坐标中转，获得了这个顶点的骨骼空间坐标。

![模型空间坐标 转 骨骼空间坐标](https://cdn.nlark.com/yuque/0/2024/webp/43256925/1730360937449-805f57ec-4ddf-4d7e-85ab-6d38c4c1d425.webp)

那么，当运行时，骨骼被动画控而旋转时，我们只需用新的转化矩阵，将骨骼空间坐标，转化为世界坐标，即可在正确的位置渲染这个点。如下图为计算顶点世界坐标的公式：

![骨骼空间坐标 转 新的世界坐标](https://cdn.nlark.com/yuque/0/2024/png/43256925/1730361555147-c892ccb7-98e6-4ec2-9cea-e1ed0f5bed29.png)

现在，我们根据这两个推断出来的公式，自行计算一个顶点的位置：

![自实现顶点位置蒙皮](https://cdn.nlark.com/yuque/0/2024/png/43256925/1730362597764-12a437a9-3c0c-4667-8c0f-3865fef5330f.png)

![bindpose](https://cdn.nlark.com/yuque/0/2024/png/43256925/1730363426000-9eb61f93-740a-4134-80ac-355a27a918cd.png)

（完整的理解这个蒙皮的过程，有助于我们达到一些效果：比如在碰撞处的皮肤造成伤口，或者精准的追击人物身上某个顶点的位置，动态构建SkinnedMeshRenderer等。再或者修改bindposes来捏脸，这是除骨骼/BS之外的另一种做法。）



顶点位置被蒙皮的过程是如何工作的，已经被我们推导出来，接下来是如何影响法线。查看开源项目，至少可以确定一件事情，SkinnedMeshRenderer会向处理顶点位置一样，以骨骼的信息，去转化模型空间下的法线。

![来自于开源项目](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134076811-db8583fc-5bbc-42a2-85d7-b6f8ea26e010.png)

查找MultiplyVertorAPI文档，明确说明了这个API用于转化方向，但是只考虑旋转。所以推测，更改根骨骼的缩放时，更多可能是因为顶点位置的变化，导致的世界坐标下法线显示不同。



也就是说<font style="background-color:#FBDE28;">SkinnedMeshRenderer不考虑骨骼缩放对顶点法线的影响</font>。

![转换方向的API](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724142994056-aca2404a-5139-45ce-99bd-1442cad87017.png)

网上找到的早期Unity4引擎的蒙皮部分的C++源码，我们可以确认这个猜想是正确的：蒙皮过程会把模型空间下的法线方向，通过骨骼的变换矩阵，转换为世界坐标下的表示。C++的MutiplyVector3和C#的MutiplyVector的实现是一致的，都是仅考虑旋转：

![Unity4.2引擎蒙皮部分源码](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724140605419-51bc832f-0398-43d3-a63d-dbf54de798d1.png)



再次梳理蒙皮过程的公式，mesh中存储的顶点法线是模型空间下的，和顶点位置蒙皮的过程类型，这个法线会先转到世界坐标系，再转到骨骼坐标系，再根据骨骼实时的转换矩阵，转为世界坐标系下，参与光照计算。

但是这最后一步的转化只考虑旋转。

为了解决下图中，顶点位置已经被缩放影响，但顶点法线没有被影响，导致的凹凸表现错误的问题，我们决定直接修改模型空间的法线，使其达到符合我们预期的效果。

| 骨骼缩放后：侧面 | 骨骼缩放后：正面 |
| --- | --- |
| ![直线为模型空间下，每个顶点对应的法线方向](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724168395334-b52c9245-ca19-4813-ba25-174fd4596318.png) | ![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1730364052970-f5926c8d-0a4e-47b0-8b8f-17d928de102b.png) |




# 二.法线重计算整体流程
以下是三个流程中重要的Mesh，我们为其命名，并在后文中统一使用该命名。可以在后文中第一次提到时，再来查看对应的意义。

_targetMesh：需要更新法线方向的Mesh

_cloneMesh：所在SkinnedMeshRenderer维持TPose, 保持和_targetMesh的mesh数据 和 骨骼数据（数量/层级/权重）同步

_bakedMesh：由_cloneMesh.BakeMesh(_bakedMesh)生成的Mesh

## 流程简述
为了计算1个点的法线，需要计算这个点，所在的每一个三角面的法线。

![点法线由共享该点的所有的面法线平均而来](https://cdn.nlark.com/yuque/0/2024/png/43256925/1730697308599-ed04914d-c3ce-4c08-89c1-648bc814cdc4.png)

而三角面的法线，是根据其中两条边的叉乘结果确定的，于是我们需要所有顶点的位置信息。这个位置信息，需要是<font style="background-color:#FBDE28;">被骨骼缩放影响后的</font>。

![三角面法线由两条边叉乘确定方向](https://cdn.nlark.com/yuque/0/2024/png/43256925/1730697961367-f8dce6a2-7aaf-4d0d-a80f-48b339c91c24.png)

我们拿到所有被骨骼缩放影响后的顶点位置，再计算顶点法线。

SkinnedMeshRenderer组件的BakeMesh可以做到这一点，使我们不必遍历每一个顶点对其进行蒙皮运算，就可以拿到所有顶点的被骨骼缩放影响后的位置。

但我们不可能根据<font style="background-color:#FBDE28;">_targetMesh</font>去BakeMesh，因为它正在给用户展示，总是在播动画，不会保持TPose。而我们需要的，是Tpose下模型空间的法线。

![被骨骼缩放影响过的网格](https://cdn.nlark.com/yuque/0/2024/png/43256925/1730698296944-4e276cbc-8435-4df6-8a6f-c4a291cc8ee6.png)



所以我们新建一个<font style="background-color:#FBDE28;">_cloneMesh</font>，保持和_targetMesh的一致，但维持TPose不动，用_cloneMesh.BakeMesh的结果<font style="background-color:#FBDE28;">_bakedMesh </font>来调用Unity提供的法线计算接口，将计算结果赋回给_targetMesh。

以下为流程图，其中切线可以暂理解为，垂直与法线的线。（图中，圆角方框为操作或方法，方框为数据变量）

![法线重计算流程图](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134076837-9081b0d8-f8de-45b2-ba83-210c675fe9ff.png)

该流程执行后，发现一些问题:

## 轴向偏差问题
观察到法线方向错误，如下图中的腹部，法线的方向呈现出有规律但错误的状态

![法线方向错误](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134082814-966d9526-1cd6-45c1-9761-ae19d93a54a0.png)



我们打开世界坐标法线的绘制模式。可以看到，人体正面的法线颜色，与地板和cube的上表面大致相同。推测，现在我们给模型赋上的法线，与正确的法线有90度的轴偏差：

![人与Cube存在轴向偏差](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134082383-80469a20-4fb3-47cd-b2a2-026b980aa6c0.png)



这让我们联想到另一个类似的事情，即通过脚本取人物模型的顶点位置，经常的会发现y轴与z轴好像反了。



这是因为我们的人体模型的Mesh是趴在地上的，再通过Root节点x轴-90度将模型站起来。

如下，_cloneMesh和_targetMesh共用一个mesh实例，并且这个mesh都是趴着的，那么理论上法线转移如果出错，问题应该处在_bakedMesh上：

![_targetMesh/_cloneMesh是趴下的](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134083664-bd7e32bd-c4e8-41d2-a3d9-4ea0ddcc9b35.png)





在场景中放一个测试用的Mesh Fillter，用于承接_bakeMesh，使_bakeMesh可以被检查。

果然，发现_bakeMesh已经站起来了，那么从一个站立的mesh上计算法线，然后赋给一个趴倒的mesh上，肯定会是会有90度的方向偏差的：

![_cloneMesh是站立的](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134082155-380461a5-48ee-4967-8595-199db10b8dee.png)



如何处理这个问题？最简单的，将_bakeMesh也趴着，这样就不用逐顶点的做矩阵运算转化这个角度。为了达到这个目的，将_cloneMesh的Root节点-90度旋转去掉，使_cloneMesh趴下：

![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134082668-b94746a4-35be-47ea-bdab-8b94a339adfc.png)

![_cloneMesh的Root节点有-90的旋转](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134088493-b42309cd-80e1-4cf5-b8b0-4e20a13e29a5.png)



此时执行一遍流程，再查看_bakeMesh，发现已经趴着了。

![_修复后的bakeMesh的朝向](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134087963-e0977694-de36-437d-b061-d34f876f44e1.png)



现在，三个(地板，cube，人物)mesh的世界法线方向大致一样，再次验证，发现结果正确：

| 调整前-错误（人与Cube的法线颜色不一致） | 调整后-正确（人与Cube的法线颜色一致） |
| --- | --- |
| ![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134082383-80469a20-4fb3-47cd-b2a2-026b980aa6c0.png) | ![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724170127082-1b5fab65-10ea-45f6-ab91-baac7254dbff.png) |




## SubMesh接缝
如下图，SubMesh接缝，unity不能很好的平滑过渡法线

![SubMesh处法线不平滑](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134089076-9ba5f3a7-9b6d-4ed8-b48e-fda22d964945.png)



这个问题的来源是由于我们将模型分成多个Mesh，在运行时动态合并，将多个SkinMesh组件合并成一个，而每个SkinMesh所有的Mesh，都会成为这个合并后的Mesh(_targetMesh)的SubMesh

![Mesh合并前，有多个蒙皮组件](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134088664-a663aa0b-f666-4298-8167-ca47ee637f5f.png)



如下图，每个颜色不同的，都是一个单独的SubMesh

![合并后的Mesh](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134094043-2e7d3a0b-6ca2-42ff-91fd-2cd9c160437e.png)

## UV接缝
如下图，UV接缝处，unity不能很好的平滑过渡法线

![如小腿处UV接缝，存在明显的法线不平滑](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134094798-45ff35d0-b0e2-41ff-94a4-a8eddb51cf98.png)

以小腿举例：

![小腿是个圆柱，展开UV时，必定会有一条分割线](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134094213-3337da78-900a-4edd-9c52-f767a7fc330b.png)



打开UV检视视图，可以看到，在箭头所指的两个顶点，在同一个位置。换句话说，这个位置有两个顶点，这两个顶点的法线在max里导出时，是被平滑过的，即，这个两个点的法线方向相同。

但重新计算后，这种同一个位置有两个顶点的情况，将不会被平滑处理，两个顶点都只从自己侧的三个三角形进行计算，而不是六个，这就是接缝处法线不平滑的原因。

SubMesh接缝处有不平滑的法线，也是同样的道理。

![小腿UV排布](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134094049-9cddb038-60f0-4c90-bd0e-eb95c88e8483.png)



查看文档，每个顶点只会从自己所在的几个三角形做平滑。

即：<font style="background-color:#FBDE28;">调用unity的计算法线接口，如果一个位置上存在多个顶点，那么计算每个顶点的法线时，仅会从自己所在的几个三角形中去做平均</font>：

![Unity计算法线接口不支持共享的顶点](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134094603-76befdcd-881d-4d0d-a972-32824ecfb4fd.png)



## 为什么同一个位置要存在多个顶点
一个Cube，最少8个顶点便可构建完成，而Unity的Cube有24个顶点。这是为了保证方块看上去是个方块，有硬边，而不是一个球，所以每个角的位置需要有3个顶点，分别由3个法线方向。

大多数情况下，一个位置多个顶点出现在硬边（maya）或者两个光滑组(max)之间，正是为了这一个位置有多个法线方向，而在一个位置，设置多个顶点。

<font style="background-color:#FBDE28;">但我们遇到的问题是剩下的小部分情况，在UV接缝处，以及SubMesh接缝处，一个位置上最少有两个顶点，而两个顶点的法线，可能需要平滑。（也可能不需要，如果这里是一个硬边，就不应该平滑）</font>

![方块可能的法线排布](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134101707-72c3d9f2-513b-4db1-9014-2fa98a5278b1.png)

![硬边方块与软边方块](https://cdn.nlark.com/yuque/0/2024/png/43256925/1730701620095-1f5d9a32-8f7f-467d-ba0f-9309d2b46320.png)



# 三.V0:支持非共享顶点的法线平滑算法
## 流程简述
如下，我们使用自定义的算法，代替掉unity计算法线的接口：

![整体流程](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134101729-0a864892-90e8-44be-bcc7-adff940f8209.png)

自定义算法实现：从每一个位置去平滑法线

![接缝处非共享顶点示意](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134101843-600678e6-f2ce-4408-a693-3b6a9d05332f.png)



## 算法实现
首先我们定义一个重要的结构：<font style="background-color:#FBDE28;">entry</font>

entry由三个int组成：verIdx(顶点索引)，triIdx(三角形索引)，subMeshIdx。

<font style="background-color:#FBDE28;">它表示了某个顶点，属于哪个三角形，属于哪个subMesh</font>。

一个顶点会对应多个entry，因为多个三角形会共享一个顶点，如上图中，1，2，3三个三角形共享一个顶点，4，5，6三个三角形共享一个顶点。



另一个重要的结构：<font style="background-color:#FBDE28;">pos</font>

pos为int3结构，<font style="background-color:#FBDE28;">表示了一个位置点</font>。如上图中，六个三角形中间的那两个顶点，具有相同的位置点。为了方便的作为字典的键，我们将这两个顶点的坐标乘上100（可配置），再取整，表示一个唯一键，即一个pos。



为了做到从每一个位置去计算法线，我们需要有一个字典（entrysMap），key是pos，value是一个entry列表。

如上图中，红圈处为一个pos（entrysMap的Key），它有6个entry（entrysMap的Value）。

![entrysMap结构](https://cdn.nlark.com/yuque/0/2024/png/43256925/1730365431675-932f36eb-7e95-4401-83d6-f3601375026a.png)



在本文第二部分我们说：”为了计算1个顶点的法线，需要计算这个顶点所在的每一个三角面的法线“。

在此我们推进一步：”为了计算1个点的法线，需要计算这个点所在的位置点，周围每一个三角面的法线“。



所以第一步，我们先计算出所有三角形的法线。并且能够根据一个entry，索引到这个三角形的法线。

同时，我们需要填充entrysMap，收集每一个位置点的entry列表。

下图表示了这个流程：

![Step1](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134101644-2c27cb48-70e1-4d75-b8c6-25da05208bf2.png)



经过上一步，我们得到了两个数据结构

1：从pos，索引到一个entry列表

2：从entry，索引到这个enrty所在三角形的法线

![Pos 及周围的几个 entry](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134101843-600678e6-f2ce-4408-a693-3b6a9d05332f.png)

现在我们遍历entrysMap的每一个pos。

然后取到这个pos的所有entry，做双循环，将外层循环的入口的三角形法线 与 内层循环的每一个入口三角形的法线尝试做平均。



对于方向来说，平均的方式就是加。下图为蓝色和白色方向平均的示意，不必担心三个颜色的向量长度问题，蓝色和白色是已经单位化的，红色向量最后也会单位化。

![红色向量为白色与蓝色的平均](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724205831791-4d6a3bf5-f6d8-4052-b69d-11045a05a11a.png)

法线夹角的大小，表示了这两个三角面的平滑度。当夹角为0，意味着两个面完全平滑，在同一个平面内。反之，如果两个法线的夹角过大，就不应该再平滑。这个阈值是一个经验值，在此处我们选择45度。

![法线夹角大小反映了面的平滑度](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724207547235-f2f8dbc9-1f43-48ad-96ad-ab629e811487.png)

下图表示了顶点法线平滑的流程：

![Step2](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724165094355-ed591489-3b35-4a44-9c0e-6ef95971e253.png)



以下是算法代码，感兴趣的同学自行阅读：

```plain
     public static void RecalculateNormals(this Mesh mesh, float angle)
    {
        var cosineThreshold = Mathf.Cos(angle * Mathf.Deg2Rad);

        var vertices = mesh.vertices;
        var normals = new Vector3[vertices.Length];

        var triNormals = new Vector3[mesh.subMeshCount][];

        var dictionary = new Dictionary<VertexKey, List<VertexEntry>>(vertices.Length);

        for (var subMeshIndex = 0; subMeshIndex < mesh.subMeshCount; ++subMeshIndex)
        {

            var triangles = mesh.GetTriangles(subMeshIndex);

            triNormals[subMeshIndex] = new Vector3[triangles.Length / 3];

            for (var i = 0; i < triangles.Length; i += 3)
            {
                int i1 = triangles[i];
                int i2 = triangles[i + 1];
                int i3 = triangles[i + 2];
                //并不是随意挑选的两条边，一定是需要i1到i2 叉乘 i1到i3
                //unity与我们约定了使用左手法则计算法线方向
                Vector3 p1 = (vertices[i2] - vertices[i1]) * 10000;
                Vector3 p2 = (vertices[i3] - vertices[i1]) * 10000;
                Vector3 normal = Vector3.Cross(p1, p2).normalized;
                int triIndex = i / 3;
                triNormals[subMeshIndex][triIndex] = normal;

                List<VertexEntry> entry;
                VertexKey key;

                if (!dictionary.TryGetValue(key = new VertexKey(vertices[i1]), out entry))
                {
                    entry = new List<VertexEntry>(4);
                    dictionary.Add(key, entry);
                }
                entry.Add(new VertexEntry(subMeshIndex, triIndex, i1));

                if (!dictionary.TryGetValue(key = new VertexKey(vertices[i2]), out entry))
                {
                    entry = new List<VertexEntry>();
                    dictionary.Add(key, entry);
                }
                entry.Add(new VertexEntry(subMeshIndex, triIndex, i2));

                if (!dictionary.TryGetValue(key = new VertexKey(vertices[i3]), out entry))
                {
                    entry = new List<VertexEntry>();
                    dictionary.Add(key, entry);
                }
                entry.Add(new VertexEntry(subMeshIndex, triIndex, i3));
            }
        }

        foreach (var vertList in dictionary.Values)
        {
            for (var i = 0; i < vertList.Count; ++i)
            {

                var sum = new Vector3();
                var lhsEntry = vertList[i];

                for (var j = 0; j < vertList.Count; ++j)
                {
                    var rhsEntry = vertList[j];

                    if (lhsEntry.VertexIndex == rhsEntry.VertexIndex)
                    {
                        sum += triNormals[rhsEntry.MeshIndex][rhsEntry.TriangleIndex];
                    }
                    else
                    {
                        var dot = Vector3.Dot(
                            triNormals[lhsEntry.MeshIndex][lhsEntry.TriangleIndex],
                            triNormals[rhsEntry.MeshIndex][rhsEntry.TriangleIndex]);
                        if (dot >= cosineThreshold)
                        {
                            sum += triNormals[rhsEntry.MeshIndex][rhsEntry.TriangleIndex];
                        }
                    }
                }

                normals[lhsEntry.VertexIndex] = sum.normalized;
            }
        }

        mesh.normals = normals;
    }
```

## 效果及算法耗时
法线被正确的计算，UV接缝处和SubMesh接缝处的法线得到平滑处理：

| 处理前：接缝处法线未平滑 | 处理后：接缝处法线得到平滑 |
| --- | --- |
| ![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724256531342-ebe60f66-ae2d-47a6-825f-526eb4926cab.png) | ![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724256377287-b84b2c7c-8740-49f4-9783-912c81302c23.png) |
| ![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1730366020722-aff262d4-b7da-4266-82af-a35d8742d127.png) | ![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724256430721-ecd6465c-9eb3-4cfc-8f54-b614ea80e787.png) |




表现问题解决之后，接下来后半段是性能问题：

PC包测试性能，计算一次19ms。

尝试了一些常用的优化手段，如容器池化，对象池化，使用EnsureCapacity提前设置容器容量，防止扩容，过滤掉重复计算的情况，甚至缓存hash值，避免多次hash计算，也最多也只能优化1倍左右。

![V0版本PC耗时](https://cdn.nlark.com/yuque/0/2024/png/43256925/1730454281695-4c4473b3-a530-41b5-92cd-6ff3388fce32.png)

# 四. 性能优化
## V1:Unity+Custom
### 流程简述
问题：CPU时间需要优化

方案：发现Unity计算法线的耗时相对较低，只要0.24ms，但是它不能平滑接缝处法线。所以我们先用unity计算一次，再自己去计算每一个接缝处的顶点法线，并覆盖unity的计算结果。

结论：CPU时间优化14倍



流程图：

![V1流程](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724341465702-c5c47c17-9412-40e6-a1d6-7494c3c3b5b1.png)

### 数据准备
在运行时去遍历所有顶点，来检索出处于接缝的顶点，是消耗很大的。由于这些接缝顶点的索引不会变化，我们将这个过程进行预处理，记录接缝处的顶点索引并保存下来。

判断是不是接缝顶点的依据是：在相同位置，但不是相同的顶点索引（UV接缝），或者不是相同的mesh（mesh接缝）：

![记录接缝顶点](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134110658-4428826b-f56b-4067-94b5-91c5c0f59aab.png)



我们记录的顶点索引是合并Mesh前的，合并之后，我们只能访问合并后的一个大的顶点数组。

为了根据记录的顶点索引，转化为合并Mesh后的顶点索引，我们需要做两件事情，用来得到每一个接缝顶点所在submesh的顶点索引偏移：

1.合并Mesh时，记录MeshName2SubMeshId

2.合并完成后，重新索引一次SubMesh顶点的起始索引，即SubMeshIdx2VerIdxStart

```plain
_cloneSkinMesh = CombineMeshUtils.CombineMesh(_cloneObj, _meshNameToSubMeshIdx);
//取到每个subMesh的开始索引
for (int i = 0; i < _cloneSkinMesh.sharedMesh.subMeshCount; i++)
    _subMeshIdxStartDic.Add(i, _cloneSkinMesh.sharedMesh.GetSubMesh(i).firstVertex);
```



### 算法耗时
PC包：0.995ms

![V1在PC包上的耗时](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134118563-c19e206a-bb52-49cd-a198-b0eb213e1d9f.png)

<font style="background-color:#FBDE28;"></font>

转到安卓手机上进行测试：12.53ms

![V1在安卓机上的耗时](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134118585-76706b0f-1d70-4cc7-80c0-1c1e23dbd1a1.png)



<font style="background-color:#FBDE28;">（本文后续出现的所有profiler截图，如无特殊标注，全部来自于安卓真机，RedmiNote 10Pro，天玑1100）</font>

### 代码实现
```plain
    public static void CustomRecalculateNormals(this Mesh mesh, int firstSubMeshIdx, int secSubMeshIdx, int firstStart, int secStart, MeshSubGapInfoItem firstInfo, MeshSubGapInfoItem secInfo, List<Vector3> normals, float cosineThreshold)
    {

        vertexEntryListPoolIdx = 0;
        CleaTempList();
        if (verticeList.Count == 0)
            mesh.GetVertices(verticeList);
        Profiler.BeginSample("CustomRecalculateNormals0_1");
        //顶点索引偏移
        foreach (var item in firstInfo.vertexIndexArray)
            needRecalculateVerticeIdxSet.Add(item + firstStart);
        foreach (var item in secInfo.vertexIndexArray)
            needRecalculateVerticeIdxSet.Add(item + secStart);
            
        //防止扩容
        dictionary.EnsureCapacity(needRecalculateVerticeIdxSet.Count);

        CalculateTriNormal(firstInfo.triangleVertexIndexArray, firstSubMeshIdx, firstStart);
        CalculateTriNormal(secInfo.triangleVertexIndexArray, secSubMeshIdx, secStart);
        Profiler.EndSample();
        Profiler.BeginSample("CustomRecalculateNormals0_2");
        //防止扩容
        vertexIdxSet.EnsureCapacity(needRecalculateVerticeIdxSet.Count);
        foreach (var item in dictionary)
        {
            var vertList = item.Value;
            for (var i = 0; i < vertList.Count; ++i)
            {
                var lhsEntry = vertList[i];
                bool isContains = vertexIdxSet.Contains(lhsEntry.VertexIndex);
                //算过的不用再算了
                if (isContains)
                    continue;
                var sum = Vector3.zero;
                for (var j = 0; j < vertList.Count; ++j)
                {
                    var rhsEntry = vertList[j];
                    if (lhsEntry.VertexIndex == rhsEntry.VertexIndex)
                    {
                        sum += GetTriNormals(rhsEntry.MeshIndex, rhsEntry.TriangleIndex);
                    }
                    else
                    {
                        var lNormal = GetTriNormals(lhsEntry.MeshIndex, lhsEntry.TriangleIndex);
                        var rNormal = GetTriNormals(rhsEntry.MeshIndex, rhsEntry.TriangleIndex);
                        var dot = Vector3.Dot(lNormal, rNormal);
                        if (dot >= cosineThreshold)
                            sum   += rNormal;
                    }
                }
                normals[lhsEntry.VertexIndex] = sum.normalized;
                vertexIdxSet.Add(lhsEntry.VertexIndex);
            }
        }
        Profiler.EndSample();
        ClearVertexEntryData();
        CleaTempList();
    }

    static void CalculateTriNormal(int[] triangleVertexArr, int subMeshIdx, int startIdx)
    {
        for (var i = 0; i < triangleVertexArr.Length; i++)
        {
            int i1 = triangleVertexArr[i] + startIdx;
            int i2 = triangleVertexArr[++i] + startIdx;
            int i3 = triangleVertexArr[++i] + startIdx;
            //该向量可能过小，叉乘出来会有问题
            Vector3 p1 = (verticeList[i2] - verticeList[i1]) * 10000;
            Vector3 p2 = (verticeList[i3] - verticeList[i1]) * 10000;
            Vector3 normal = Vector3.Cross(p1, p2);

            SetTriNormals(subMeshIdx, normal);
            int triIndex = i / 3;
            List<VertexEntry> entry;
            Vector3Int key;
            
            //仅使用接缝处顶点的作为作为键
            if (needRecalculateVerticeIdxSet.Contains(i1))
            {
                if (!dictionary.TryGetValue(key = GetVertexKey(verticeList[i1]), out entry))
                {
                    entry = GetVertexEntryList();
                    dictionary.Add(key, entry);
                }
                entry.Add(GetVertexEntry(subMeshIdx, triIndex, i1));
            }

            if (needRecalculateVerticeIdxSet.Contains(i2))
            {
                if (!dictionary.TryGetValue(key = GetVertexKey(verticeList[i2]), out entry))
                {
                    entry = GetVertexEntryList();
                    dictionary.Add(key, entry);
                }
                entry.Add(GetVertexEntry(subMeshIdx, triIndex, i2));
            }

            if (needRecalculateVerticeIdxSet.Contains(i3))
            {
                if (!dictionary.TryGetValue(key = GetVertexKey(verticeList[i3]), out entry))
                {
                    entry = GetVertexEntryList();
                    dictionary.Add(key, entry);
                }
                entry.Add(GetVertexEntry(subMeshIdx, triIndex, i3));
            }
        }
    }
```



## V2：Unity + Custom_Job
### 方案简述
问题：单次执行的10ms的CPU时间需要优化

方案：使用IJob+Burst+Unity.Mathematics进行优化，将CustomRecalculateNormals改为IJob写法。期望IJob带来多线程并行，以及Burst+Unity.Mathematics带来SIMD优化，以大幅降低算法执行时间。

结论：耗时优化效果不明显。





![SIMD单指令多数据](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134125618-6c344e33-8632-46c1-8c2e-f8cdbbf05806.png)

### 使用Job实现算法
如下图，将右侧“三角形法线计算 + entry收集”的算法实现，修改完左侧job方式的实现。可以看到在写法上，算法本身的流程并没有大的修改，只是数学库，向量表示，以及容器的不同：

![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134119327-4d37481a-ad84-4189-b4cc-2e219413921c.png)



顶点法线计算：

![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134119230-b76f40ef-6efb-4438-b051-0ade45fc5009.png)

### 效果及算法耗时
初步测试，算法执行时间约提升1倍，但接缝处表现不对。

优化幅度和表现都不符合预期，根据打点，发现了一些影响性能的代码实现细节：

#### 1.Native容器-托管容器转化消耗
Jobs只能使用Native容器，但mesh.GetNormals没有Native重载，List2NativeList，NativeList2List存在较大耗时。

查找相关接口，发现jobs配套了一组mesh数据修改接口：

![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134126611-b0770ca2-f72b-4e40-9ffa-9c7c74fbe358.png)

Mesh.AcquireReadOnlyMeshData获取只读数据，Mesh.AllocateWritableMeshData分配一个临时可写的，拷贝到AllocateWritableMeshData后修改，修改完用Mesh.ApplyAndDisposeWritableMeshData设置回去。

由于ApplyAndDisposeWritableMeshData方式需要定义顶点形状，包括位置，法线，切线，uv，骨骼，权重等，所以这里只采用AcquireReadOnlyMeshData，获取顶点位置和法线信息。

```plain
//NativeArray<float3> normals = new NativeArray<float3>(_bakedMesh.vertexCount, Allocator.TempJob);
//for (int i = 0; i < _normals.Count; i++)
//{
//    normals[i] = _normals[i];
//}
//NativeArray<VertexStruct> verts = new NativeArray<VertexStruct>(_bakedMesh.vertexCount, Allocator.TempJob);
//for (int i = 0; i < _verts.Count; i++)
//{
//    verts[i] = _verts[i];
//}
Mesh.MeshDataArray data = Mesh.AcquireReadOnlyMeshData(_bakedMesh);
var verts = data[0].GetVertexData<VertexStruct>();
```



#### 2.并行失败：IJobParallelFor vs IJob
![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134126681-b1b69c91-455f-49ee-81ad-ffaf0c907a38.png)

查看文档，发现IJob.Schedule会调度到其他线程(单线程)，IJob.Run会在主线程执行，不用考虑多个线程间的竞争关系。但是这相当于把完整的循环放到一个线程去运行，无法达到并行的目的。

同时，我们注意到IJobParallelFor.Schedule是允许多线程并行并行的接口，它不方便的地方在于，我们需要考虑，多个线程对同一容器的写入，会存在竞争问题。



![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134126711-043e8306-b6d2-4b15-b54d-0abb1ffe4de5.png)

![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134127195-c942c1e9-59e8-428a-b9e6-0c9633192333.png)

#### 3.效果问题
由于我们Map的value是FixedList128Bytes，也是一个Native容器，而所有的Native容器都是结构体。所以改完Value之后，需要往回赋值，这非常违背我们使用C#数据结构的习惯和直觉。

这个问题直接导致下一步计算顶点法线的工作量大大降低，同时平滑失败。

修复后，耗时增加，与V1版本耗时差不多

```plain
if (needRecalculateVerticeIdxSet.Contains(i1))
{
    if (!dictionary.TryGetValue(key = new int3(math.round(i1 * 100)), out entry))
    {
        entry = new FixedList128Bytes<int3>();
        dictionary.Add(key, entry);
    }
    entry.Add(new int3(subMeshIdx, triIndex, i1));
    //Native容器都是结构体，当嵌套时，需要注意往回赋。
    dictionary[key] = entry;
}
```



#### 4.Native容器申请释放消耗
注意到下图Clear点消耗较高，其实现是释放一些Native容器，考虑使用Allocator.Persistent取代Allocator.TempJob，进行Native容器复用

![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1730703107243-ae840a8b-60f0-4ee2-a659-ec995ae91735.png)

#### 5.Job数量过多
发现每个接缝开一个job，单个job处理的数据量过小，即使成功并行，也发挥不出job的优势，反而带来了线程调度的开销：考虑将所有接缝信息汇总在一起，调用一次算法

![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134126652-b4648b08-df61-4af9-9c34-2ba6fc6531e6.png)

#### 6.hash函数
发现算法本身有很大一部分耗时在问题3的hash函数：考虑到一个位置点，对应的entry列表，仅需要在mesh发生变化时计算一次，将entry收集放在换装后。（在大规模循环时，hash算法往往时最耗时的）

```plain
if (needRecalculateVerticeIdxSet.Contains(i1))
{
    if (!dictionary.TryGetValue(key = new int3(math.round(i1 * 100)), out entry))
    {
        entry = new FixedList128Bytes<int3>();
        dictionary.Add(key, entry);
    }
    entry.Add(new int3(subMeshIdx, triIndex, i1));
    //Native容器都是结构体，当嵌套时，需要注意往回赋值
    dictionary[key] = entry;
}
```

## V3：Unity+Custom_NewData
问题：根据V2版本的问题及设想的解决方式，继续优化10ms左右的CPU时间

方案：将entrysMap的收集从算法中去除，初始化/换装时将所有接缝处的顶点收集到一起。将收集后的顶点作为输入，1次调用计算所有接缝

结论：换装时刷新数据耗时过高，法线计算本身耗时大幅下降。



<font style="background-color:#FBDE28;">一个位置点，有哪些顶点，是确定的，不会随着骨骼的缩放有所不同</font>。那么收集entryMap这一步，只需要在Mesh发生变化的时候执行，具体到我们项目中，也就是换装的时候。

同时，回顾之前的算法，我们其实并不需要SubMeshId这个东西出现在算法中，只需要三角形索引，我们就能索引到一个三角形的法线。

于是我们决定<font style="background-color:#FBDE28;">在换装时，汇总所有接缝处的顶点及三角形，收集一次entryMap。</font>

<font style="background-color:#FBDE28;">而计算法线的算法，只计算法线，不做多余的事情</font>。

![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134135819-e0b86ff5-8b6d-45a0-98ff-45321fd64389.png)



<font style="background-color:#FBDE28;">V3算法不使用Job或者Burst，仅是将entryMap的收集放到换装.</font>

截取一帧，V3版本的对比耗时数据：

V3: 5.82ms（3.36ms + 2.25ms）

其中3.36ms的消耗，发生在换装，相对捏人骨骼调整来说，这应该是一个相对低频的操作。

2.25ms是整个法线计算流程的消耗，其中我们自实现的法线计算，仅耗时0.822ms。

![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134135790-8b62f2b9-3806-4848-bb28-31d3f1cff2ce.png)

![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134135723-0d702063-0d2c-48a0-9df9-2cd346c27d58.png)



如上图，我们需要继续对V3版本分两个方向进行优化：

1.RefreshMeshData：即收集EntryMap

2.法线计算算法优化：V3的0.822ms算法耗时。



## V4：Unity+Custom_NewData_Job
问题：换装时刷新数据耗时过高。法线计算虽然已经降低很多，但是未采用多线程，可能仍有优化空间。

方案：将entrysMap的收集转为离线预处理，运行时触发换装后，将多个小的entryMap通过顶点索引偏移，合并为一个大的entryMap。同时采用job+Burst对V3进行优化。

结论：RefreshMeshData耗时优化8倍，法线计算耗时优化1倍。



首先我们对耗时0.822ms的法线计算算法进行优化：

我们需要使用IJobParallelFor，进行多线程并行计算，包括三角形的法线计算和顶点法线的计算。顶点法线计算依赖于三角形的法线计算结果，在这里，我们拆分成两个job

### 法线算法并行化
#### 1.计算三角形法线
考虑每一个最小单位要执行的事情，同时这个单位的输出的写入位置，不能与其他最小单位的输出写在同一个位置。

在这里，我们使用1个三角形的法线计算，作为最小单位，使用三角形的索引（非顶点索引）作为写入数组的索引，这样就保证了不会多线程冲突。但unity不会知道这个事情，它的安全检查会这里有竞争的风险，于是编译报错。

所以我们加上NativeDisableContainerSafetyRestriction，告诉unity不必担心，我们已经规划好了，不会有写入的冲突。

![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134135842-09d78b4b-e483-4fc7-9197-6c508abf5bd5.png)



#### 2.计算顶点法线
我们这里将最小单位定义为，计算一个顶点的法线。

并行执行成功：

![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134135817-b9c6e236-70db-4f73-b871-dea5a14d46dc.png)

### 调度方式及耗时对比
虽然并行成功，但不代表并行一定是最优解。多线程或有调度消耗，可能抵消优化效果。

于是同帧执行多种调度方式。查看多帧数据，在新的数据组织方式下，<font style="background-color:#FBDE28;">不使用job(0.82) > job-调度到其他线程(0.69) > job-直接主线程执行(0.59) > job-并行(0.43)</font>

同时考虑到数据量可能会继续变大，在此V4确定采用job并行方案。

![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134145574-0294bf5f-dee1-4f80-990e-f16d50e182ac.png)

![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134145569-c00ff4e2-9846-40a2-98e0-a673f231f1b2.png)

![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134145574-db0d0367-fdac-40fd-ab38-d77ec3aab8d9.png)

### 代码实现
以下为Job并行版本算法代码，感兴趣的同学自行阅读：

```plain
public class NormalSolver5
{

    public static JobHandle CustomRecalculateNormals(NativeArray<VertexStruct> vertices, 
                                                     NativeList<int> triList, 
                                                     NativeArray<float3> triNormalList, 
                                                     NativeHashMap<int3, FixedList512Bytes<int2>> entrys, 
                                                     NativeList<int> needRecalculateVerticeListWithJob, 
                                                     NativeHashMap<int, int3> verIdxToPosKeyMapWithDic, 
                                                     float cosineThreshold)
    {
        
        var job = CalculateTriNormal(vertices, triList, triNormalList);
        return CalculateSmoothNormal(vertices ,triNormalList, entrys, needRecalculateVerticeListWithJob, verIdxToPosKeyMapWithDic, cosineThreshold, job);
    }


    [BurstCompile(CompileSynchronously = true)]
    struct CalculateSmoothNormalJob : IJobParallelFor
    {
        public float cosineThreshold;
        [ReadOnly]
        public NativeHashMap<int3, FixedList512Bytes<int2>> dictionary;
        [ReadOnly]
        public NativeArray<float3> triNormalList;

        [WriteOnly]
        [NativeDisableContainerSafetyRestriction]
        public NativeArray<VertexStruct> verticeList;

        [ReadOnly]
        public NativeList<int> needRecalculateVerticeListWithJob;

        [ReadOnly]
        public NativeHashMap<int, int3> verIdxToPosKeyMapWithDic;
        public void Execute(int idx)
        {
            var verIdx = needRecalculateVerticeListWithJob[idx];
            var vertList = dictionary[verIdxToPosKeyMapWithDic[verIdx]];
            for (var i = 0; i < vertList.Length; ++i)
            {
                var lhsEntry = vertList[i];
                if (lhsEntry[1] != verIdx)
                    continue;
                float3 sum = 0.0f;
                for (var j = 0; j < vertList.Length; ++j)
                {
                    var rhsEntry = vertList[j];
                    if (lhsEntry[1] == rhsEntry[1])
                        sum += triNormalList[rhsEntry[0]];
                    else
                    {
                        var lNormal = triNormalList[lhsEntry[0]];
                        var rNormal = triNormalList[rhsEntry[0]];
                        var dot = math.dot(lNormal, rNormal);
                        if (dot >= cosineThreshold)
                            sum += rNormal;
                    }
                }

                var vert = verticeList[lhsEntry[1]];
                vert.normal = math.normalizesafe(sum);
                verticeList[verIdx] = vert;
                break;
            }
        }
    }



    [BurstCompile(CompileSynchronously = true)]
    struct CalculateTriNormalJob : IJobParallelFor
    {
        [ReadOnly]
        public NativeList<int> triangleVertexArr;
        [ReadOnly]
        public NativeArray<VertexStruct> verticeList;

        [WriteOnly]
        [NativeDisableContainerSafetyRestriction]
        public NativeArray<float3> triNormalList;

        public void Execute(int idx)
        {
            int i1 = triangleVertexArr[idx * 3];
            int i2 = triangleVertexArr[idx * 3 + 1];
            int i3 = triangleVertexArr[idx * 3 + 2];
            float3 p1 = (verticeList[i2].pos - verticeList[i1].pos) * 10000;
            float3 p2 = (verticeList[i3].pos - verticeList[i1].pos) * 10000;
            float3 normal = math.cross(p1, p2);
            triNormalList[idx] = normal;
        }
    }

    static JobHandle CalculateTriNormal(NativeArray<VertexStruct> vertices, NativeList<int> triList, NativeArray<float3> triNormalList)
    {
        CalculateTriNormalJob job = new CalculateTriNormalJob();
        job.triangleVertexArr = triList;
        job.triNormalList = triNormalList;
        job.verticeList = vertices;
        var handle = job.Schedule(triList.Length/3, 32);
        return handle;
    }
    
    static JobHandle CalculateSmoothNormal(NativeArray<VertexStruct> vertices, 
                                           NativeArray<float3> triNormalList, 
                                           NativeHashMap<int3, FixedList512Bytes<int2>> entrys, 
                                           NativeList<int> needRecalculateVerticeListWithJob, 
                                           NativeHashMap<int, int3> verIdxToPosKeyMapWithDic, 
                                           float cosineThreshold, 
                                           JobHandle depHandle)
    {
        CalculateSmoothNormalJob job = new CalculateSmoothNormalJob();
        job.dictionary = entrys;
        job.verticeList = vertices;
        job.cosineThreshold = cosineThreshold;
        job.triNormalList = triNormalList;
        job.needRecalculateVerticeListWithJob = needRecalculateVerticeListWithJob;
        job.verIdxToPosKeyMapWithDic = verIdxToPosKeyMapWithDic;
        var handle = job.Schedule(needRecalculateVerticeListWithJob.Length, 32, depHandle);
        return handle;
    }
}

```



### RefeshMeshData 预处理+Burst
下图中V3的0.82ms的法线计算算法优化结束后，继续来优化V3的RefreshMeshData的3.36ms

![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134145524-73252f19-1daa-4188-8ac0-40470b62b93b.png)



性能打点发现，将顶点坐标转为位置点，并填充entryMap部分占据不小的开销，于是先来优化这块代码，同时实验一下job提供的支持并行写入的字典。

![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134145578-ba99ea60-6767-4f0c-af3e-a54cd9299063.png)

#### 支持并行写入的容器
使用job并行写入字典，通过profiler发现每个job的耗时都很高（约1ms），推测是原子操作的线程竞争问题，放弃使用job。下图代码仅示意并行容器的写入和读取方式：

```plain
public NativeParallelMultiHashMap<int3, FixedList512Bytes<int2>> entrys;
public void Execute(int idx)
{
    //写
    var parallelWriter = entrys.AsParallelWriter();
    parallelWriter.Add(new int3(0,0,0), new FixedList512Bytes<int2>());
    
    //读
    int3 key = new int3(0,0,0);
    FixedList512Bytes<int2> list;
    if (entrys.TryGetFirstValue(key, out FixedList512Bytes<int2> firstValue, out NativeParallelMultiHashMapIterator<int3> it))
    {
        //list.Add --> firstValue;
        while(entrys.TryGetNextValue(out FixedList512Bytes<int2> nextValue, ref  it))
        { 
            //list.Add --> nextValue;
        }
    }
}
```



#### 预收集entry，运行时只合并
<font style="background-color:#FBDE28;">对于每一个单独的mesh来说，它接缝处的点位信息是可以预先收集的，因为都是相同的root点。</font>

<font style="background-color:#FBDE28;">所以我们提前收集每一个Mesh上接缝处的entrys，运行时，将在同一个位置的进行合并在一起。可以理解为将多个小字典，合并成一个大字典，即entryMap。</font>

![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134155712-115b1a9a-23b4-490c-931a-7513efeb05a1.png)



为了后续能够方便的进行job化或者burst化，将entry存储为<font style="background-color:#FBDE28;">扁平化的数组</font>：

![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134155724-2ce32e8c-7572-4482-bf99-2b86aad58f06.png)



执行时间得到了大幅度的优化：

![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134155728-1ae5e605-9980-4ce4-bc2c-b0a46019b870.png)



#### 使用Burst对合并方法进行优化
> <font style="color:rgb(51, 51, 51);">Burst 是一个编译器，您可以将其与 Unity 的</font>[作业系统](https://docs.unity3d.com/Manual/JobSystem.html)<font style="color:rgb(51, 51, 51);">一起使用，以创建可增强和改善应用程序性能的代码。它将您的代码从 IL/.NET 字节码转换为使用 </font>[LLVM 编译器](https://llvm.org/)<font style="color:rgb(51, 51, 51);">的优化原生 CPU 代码。</font>
>

既然Job的并行写入并不适合这里，那么如果单独使用Burst+Unity.Mathematics，可能仍对方法的执行有优化效果。

结论：

Burst版本合并耗时：<font style="background-color:#FBDE28;">0.47ms</font>		（+0.22ms CopyData）

未使用Burst版本合并耗时：<font style="background-color:#FBDE28;">1.52ms</font>

![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134166409-a7003b04-b6d9-4670-ae3e-6aca85b20546.png)





如何将一个普通的方法，该写成符合Burst限制的方法，同时使用一些语法，来提示Burst进行编译优化：

![Editor下Burst使代码速度优化了10倍](https://cdn.nlark.com/yuque/0/2024/png/43256925/1730716562346-c219e4f5-b422-4c28-a170-18555ef1bc93.png)



##### 提示
使用Unlikely（大概率不发生），Likely（大概率发生），Assume（确定），NoAlias（没有别名，即不用考虑多个数据结构指向同一地址），ReadOnly（只读）等来提示Burst对程序进行优化

![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134179143-62d10d6c-5b84-4602-b8d2-a097cb50a529.png)

![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1730784953577-44e119f6-37a2-4559-907b-9ccff9870644.png)

![Editor下NoAlias效果对比](https://cdn.nlark.com/yuque/0/2024/png/43256925/1730715566344-a478c594-b44a-4c46-a7f3-0f031e4f19e8.png)



从BurstInspector(关注紫色部分)来看，左侧实现了单指令多数据的优化。

如下图所示，每次偏移32Byte，调用一次指令，每循环偏移4次，单次循环就处理了128Byte数据的加法。

1个int32为4Byte，即循环的次数被降低为原来的1/32。

| 添加NoAliasAttribute | 不添加NoAliasAttribute |
| --- | --- |
| ![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1730715652359-a7460c55-b0cb-4899-84b4-6c76cb7ad281.png) | ![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1730715672494-d3454740-4929-43b6-a5a9-f4be6bf098aa.png) |




Likely绝大部分帧有效果，但效果不是特别明显：

![Editor下NoAlias提示概率测试](https://cdn.nlark.com/yuque/0/2024/png/43256925/1730716019203-73fc8eb5-f40b-4343-8ad5-6051dfdfec22.png)

| Likely | Unlikely |
| --- | --- |
| ![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1730787240460-fa533b1b-ff27-48c2-b890-86f1f4e3159f.png) | ![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1730787329183-e59fb651-c6fb-4c05-831f-ca6f180f681c.png) |


由上图表可以明显看出，Likely/Unlikely通过人类提前标识表达式为真的概率，来提示Burst调整指令，降低指令跳转的概率，以此来进行优化。

##### if-eles / math.select
优先使用math.select代替if-else，<font style="color:rgb(51, 51, 51);">就像shader用lerp代替if-else一样</font>。或者使用三元运算符替代is-else。因为if-else结构一定会打断SIMD

![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134166900-0be4485f-f274-41e1-8fc5-bd7cb6e4aa09.png)

![meth.select的实现](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134166469-dbd454a0-cef6-445a-bd0f-208ca4c11928.png)

![Editor下三元对比测试](https://cdn.nlark.com/yuque/0/2024/png/43256925/1730716331229-71ac1e4b-a607-43b6-98be-ec301fa024d0.png)

| 三元表达式 | if-else |
| --- | --- |
| ![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1730788655342-cc0c81da-0c91-43e1-ae44-ada53638d7b8.png) | ![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1730788687603-28202865-f582-4d9c-b77f-8fd19da29f98.png) |


##### 验证循化是否向量化成功
有时候加了一堆[NoAlias][ReadOnly]等特性，人类自信能够SIMD成功，但事实上一个小细节就会导致SIMD失败。

将Unity.Burst.CompilerServices.Loop.ExpectVectorized()写进循环内部，如果Burst编译后报错，证明其向量化失败。

如下图，实现将一个NativeArray<int>里的元素按序追加进NativeList<int>，并且每一个元素的值都要加上一个数字(SubMesh起始顶点索引偏移)。

左侧最简单的写法，向量化失败，因为其调用Add。右侧改写成先添加长度范围，再按位赋值后，向量化成功。

![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1730783753992-f27cc841-a070-455d-9589-bad6e8092dec.png)



##### 输入输出容器转化
Burst方法不允许使用托管类型的输入和输出，为此，我们需要将输入从托管内存复制到Native容器。

经过实验，在数据量比较大的时候，使用Copy将数组拷贝到可复用的Native容器，代替使用循环方式进行赋值，同时记录真实的数组长度是更快速的做法（或者反序列化时，将序列化的托管数据结构转化为Native容器，但是有更大的内存泄漏的风险）：

![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1724134178631-5259e94c-55b0-4c81-bf0b-6e6bfd794593.png)

![Editor下两千万位int拷贝](https://cdn.nlark.com/yuque/0/2024/png/43256925/1730717417270-76ff4fd8-4aea-49e1-bb07-8c2a82520a18.png)

## V5：计算1个位置点下所有顶点的法线为最小单位
问题：V4的job以计算1个顶点的法线作为最小单位，粒度过小，数据组织过程较为复杂

方案：采用计算1个位置点所有顶点的法线为最小单位，因为1个顶点不可能即在A位置点，又在B位置点，所以这样也能避免写入竞争。

结论：由于更改了最小计算单位，所以少了几个中转索引的数据结构。所以顶点法线计算耗时，换装时数据重新组织数据耗时，都得到了小幅度优化。![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1730690011136-b406f9d2-77a9-476f-80f3-cd453fc685e7.png)

最终V5版本的代码实现，相对前几个版本更为精简高效：

```plain
[BurstCompile]
[MethodImpl(MethodImplOptions.NoInlining)]
static void FillEntryList3([NoAlias]ref NativeHashMap<int3, int> entrysWithJob,
                         [NoAlias]ref NativeList<int> triIdxListWithJob,
                         [NoAlias] ref NativeList<FixedList512Bytes<int2>> valueList,
                         [NoAlias] ref NativeList<int> needRecalculateVerticeListWithJob,
                         [NoAlias] ref MeshArgs2 meshArgs
                          )
{ 
    int idxStart = meshArgs.idxStart;
    int triCount = triIdxListWithJob.Length / 3;
    var startIdx = triIdxListWithJob.Length;
    triIdxListWithJob.Resize(triIdxListWithJob.Length + meshArgs.triCount, NativeArrayOptions.UninitializedMemory);
    for (int i = 0; i < meshArgs.triCount; i++)
    { 
        triIdxListWithJob[startIdx + i] = meshArgs.tris[i] + idxStart;
    }
    startIdx = needRecalculateVerticeListWithJob.Length;
    needRecalculateVerticeListWithJob.Resize(needRecalculateVerticeListWithJob.Length + meshArgs.versCount, NativeArrayOptions.UninitializedMemory);
    for (int i = 0; i < meshArgs.versCount; i++)
    { 
        needRecalculateVerticeListWithJob[startIdx + i] = meshArgs.vers[i] + idxStart;
    }
    int offfset = 0;
    int2 entryOffset = new int2(triCount, idxStart);
    for (int i = 0; i < meshArgs.entryKeyCount; i++)
    {
        var intKey = meshArgs.entryKeyList[i];
        bool has = entrysWithJob.ContainsKey(intKey);
        int idx = has ? entrysWithJob[intKey] : -1;
        var list =  has ? valueList[idx] : new FixedList512Bytes<int2>();
        var count = meshArgs.entryCountList[i];
        for (int j = 0; j < count; j++)
            list.Add(meshArgs.entryValueList[j + offfset] + entryOffset);
        if (has)
            valueList[idx] = list;
        else
        { 
            entrysWithJob.Add(intKey, valueList.Length);
            valueList.Add(list);
        }
        offfset += count;
    }
}
```



```plain
using Unity.Burst;
using Unity.Jobs;
using Unity.Collections;
using Unity.Mathematics;
using Unity.Collections.LowLevel.Unsafe;
using UnityEngine;

public class NormalSolver8
{
    public static JobHandle CustomRecalculateNormals(NativeArray<VertexStruct> vertices, 
                                                     NativeList<int> triList, 
                                                     NativeArray<float3> triNormalList, 
                                                     NativeList<FixedList512Bytes<int2>> valueList, 
                                                     float cosineThreshold)
    {
        
        var job = CalculateTriNormal(vertices, triList, triNormalList);
        return CalculateSmoothNormal(vertices ,triNormalList, valueList, cosineThreshold, job);
    }

    [BurstCompile(CompileSynchronously = true)]
    struct CalculateSmoothNormalJob : IJobParallelFor
    {
        public float cosineThreshold;
        [ReadOnly]
        public NativeArray<float3> triNormalList;

        [WriteOnly]
        [NativeDisableContainerSafetyRestriction]
        public NativeArray<VertexStruct> verticeList;
        [ReadOnly]
        public NativeList<FixedList512Bytes<int2>> valueList;
        public void Execute(int idx)
        {
            var entryList = valueList[idx];
            for (var i = 0; i < entryList.Length; ++i)
            {
                var lhsEntry = entryList[i];
                if (verticeList[lhsEntry[1]].pos.x > 9999)
                    continue;
                float3 sum = 0.0f;
                for (var j = 0; j < entryList.Length; ++j)
                {
                    var rhsEntry = entryList[j];
                    if (lhsEntry[1] == rhsEntry[1])
                        sum += triNormalList[rhsEntry[0]];
                    else
                    {
                        var lNormal = triNormalList[lhsEntry[0]];
                        var rNormal = triNormalList[rhsEntry[0]];
                        var dot = math.dot(lNormal, rNormal);
                        if (dot >= cosineThreshold)
                            sum += rNormal;
                    }
                }

                var vert = verticeList[lhsEntry[1]];
                vert.normal = math.normalizesafe(sum);
                vert.pos.x = 10000;
                verticeList[lhsEntry[1]] = vert;
            }
        }
    }

    [BurstCompile(CompileSynchronously = true)]
    struct CalculateTriNormalJob : IJobParallelFor
    {
        [ReadOnly]
        public NativeList<int> triangleVertexArr;
        [ReadOnly]
        public NativeArray<VertexStruct> verticeList;

        [WriteOnly]
        [NativeDisableContainerSafetyRestriction]
        public NativeArray<float3> triNormalList;

        public void Execute(int idx)
        {
            int i1 = triangleVertexArr[idx * 3];
            int i2 = triangleVertexArr[idx * 3 + 1];
            int i3 = triangleVertexArr[idx * 3 + 2];
            float3 p1 = (verticeList[i2].pos - verticeList[i1].pos) * 10000;
            float3 p2 = (verticeList[i3].pos - verticeList[i1].pos) * 10000;
            float3 normal = math.normalizesafe(math.cross(p1, p2));
            triNormalList[idx] = normal;
        }
    }

    static JobHandle CalculateTriNormal(NativeArray<VertexStruct> vertices, NativeList<int> triList, NativeArray<float3> triNormalList)
    {
        CalculateTriNormalJob job = new CalculateTriNormalJob();
        job.triangleVertexArr = triList;
        job.triNormalList = triNormalList;
        job.verticeList = vertices;
        var handle = job.Schedule(triList.Length/3, 24);
        return handle;
    }
    
    static JobHandle CalculateSmoothNormal(NativeArray<VertexStruct> vertices, 
                                           NativeArray<float3> triNormalList, 
                                           NativeList<FixedList512Bytes<int2>> valueList,  
                                           float cosineThreshold, 
                                           JobHandle depHandle)
    {
        CalculateSmoothNormalJob job = new CalculateSmoothNormalJob();
        job.verticeList = vertices;
        job.cosineThreshold = cosineThreshold;
        job.triNormalList = triNormalList;
        job.valueList = valueList;
        var handle = job.Schedule(valueList.Length, 32, depHandle);
        return handle;
    }
}

```

## 性能优化效果总结
为了更准确的得到优化效果，降低偶然性，使用UWA进行真机性能打点测试：

![UWA测试结果](https://cdn.nlark.com/yuque/0/2024/png/43256925/1730799638444-8280ea3a-a4af-4b40-9f95-2e097576d2cb.png)

测试环境：<font style="background-color:#FBDE28;">RedmiNote 10Pro，天玑1100</font>

![](https://cdn.nlark.com/yuque/0/2024/png/43256925/1730456856973-9f7de6a8-3b8b-42ca-9521-94d9437176f8.png)



数据规模：55个接缝，1319个接缝顶点，2556个接缝三角形。最新的裸模接缝顶点相较于当前测试的数据规模会有所升高。



算法执行次数：800次



平均单次耗时表：

|  | 算法耗时（ms） | UnityAPI（ms） | 刷新数据-换装时（ms） |
| --- | --- | --- | --- |
| V0（自行计算所有顶点的法线） | 112.94 | 0 | 0 |
| V1（先用unity计算，再自行计算接缝） | 8.02 | 1.75 | 0 |
| V2（使用Job对接缝处法线计算进行优化） | 6.85 | 1.77 | 0 |
| V3（换装时计算entryMap，无Job） | 1.10 | 1.91 | 4.36 |
| V4（预处理entryMap，换装时合并，使用多线程Job+Burst） | 0.51 | 1.73 | 0.87 |
| V5（在V4的基础上，改变最小计算单位） | 0.43 | 1.77 | 0.68 |




V1

优化效果：112.94ms--->8.02ms

优化方案：大幅度减少需要计算的顶点，只自行计算处理接缝处的顶点。从自行计算17486个顶点的法线，缩减为只处理55个接缝处1319个顶点的法线。

启发：数据批量相对较大，需要尝试使用jobs多线程处理。



V2

优化效果：8.02ms--->6.85ms

优化方案：每个接缝开Job，分成 三角形法线计算Job 和 顶点法线平滑Job

启发：法线Jobs的多线程用法不对，entryMap收集频率不合理，Native数据结构和托管数据结构的转化问题



V3

优化效果：6.85ms--->1.10ms    

   0ms--->4.36ms(刷新数据)

优化方案：将entryMap的收集抽出去，放到换装结束时。未使用job。

启发：刷新数据耗时过高，法线计算在主程序耗时1.13ms，有尝试多线程的必要。



V4：

优化效果：1.10ms--->0.51ms    

   4.36ms--->0.87ms(刷新数据)

优化方案：正确使用多线程计算法线。将位置点和顶点的归属关系，提前序列化下来。

启发：job粒度过小，在避免竞争的前提下，有粒度更大的方式。



V5：

优化效果：0.51ms--->0.43ms    

   0.87ms--->0.68ms(刷新数据)

优化方案：计算一个位置点的所有顶点法线作为最小计算单位，提高每个job的工作量，减少job批次数量，减少几个中间转化索引的数据结构。

添加Unity.Burst.CompilerServices.Loop.ExpectVectorized进行检测，并优化两个循环至可向量化。

